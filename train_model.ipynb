{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2g2ZJ8nJ4At_"
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time\n",
    "import os.path as path\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2023)\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 16 \n",
    "CHANNELS = 1\n",
    "num_classes = 5\n",
    "img_height = 32\n",
    "img_width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOM0fJ9T4LxP"
   },
   "outputs": [],
   "source": [
    "def load_data(datasetPath):\n",
    "\n",
    "    # load data from the pickle file\n",
    "    with open(datasetPath, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "\n",
    "\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    print(\"\\n[INFO] splitting dataset into train and validation sets\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=22)\n",
    "\n",
    "    print(\"\\n[INFO] reshaping images\")\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_height, img_width, CHANNELS)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_height, img_width, CHANNELS)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WY9RVxzBKR_V"
   },
   "outputs": [],
   "source": [
    "def build_model_1(MODEL_NAME):\n",
    "    print(\"\\n[INFO] creating model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(img_height, img_width, CHANNELS)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\", input_shape=(img_height, img_width, CHANNELS)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(100, (5, 5), padding=\"same\", input_shape=(img_height, img_width, CHANNELS)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(20, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(MODEL_NAME):\n",
    "    print(\"\\n[INFO] creating model\")\n",
    "    model = Sequential()\n",
    "\n",
    "    chanDim  = 1\n",
    "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=(img_height, img_width, CHANNELS)))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3),  activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "        \n",
    "    model.add(Conv2D(64, (3, 3),  activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet5():\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(6,kernel_size=(5,5),strides=(1,1),activation='relu',input_shape=(img_height,img_width,CHANNELS),padding='same'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3QXW2dXKWQ2"
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history,MODEL_NAME):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # print(model_history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(len(model_history.history['accuracy']),10),np.arange(len(model_history.history['accuracy']),10))\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(len(model_history.history['loss']),10),np.arange(len(model_history.history['loss']),10))\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "    fig.savefig(f'./Model_graph/{MODEL_NAME}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-Yu026Z4Y3p"
   },
   "outputs": [],
   "source": [
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMoN0IL6KcE7"
   },
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_test, y_test,MODEL_NAME):\n",
    "\n",
    "    print(\"\\n[INFO] model training starting\\n\")    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
    "                  optimizer=keras.optimizers.Adam(), \\\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # start timer\n",
    "    start = time.time()\n",
    "\n",
    "    # checkpoint\n",
    "    outputFolder = f'./output-checkpoint/{MODEL_NAME}'\n",
    "    if not os.path.exists(outputFolder):\n",
    "        os.makedirs(outputFolder)\n",
    "\n",
    "    filepath = outputFolder + \"/weights-{epoch:02d}-{val_acc:.2f}.h5py\"\n",
    "\n",
    "    epoch_num = 50\n",
    "    file_ini = outputFolder + '/weights-' + str(epoch_num) + '*'\n",
    "    filename =  glob.glob(file_ini)\n",
    "    K.set_value(model.optimizer.learning_rate, 0.0001)\n",
    "    # checkpoint creation for saving model\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \\\n",
    "                            save_best_only=False, save_weights_only=True, \\\n",
    "                            mode='auto', period=10)\n",
    "\n",
    "    # tensorboard logs for visualization\n",
    "    tbCallBack = TensorBoard(log_dir='./logs', batch_size=BATCH_SIZE, \\\n",
    "                write_grads=True, histogram_freq=2, write_graph=True, write_images=True)\n",
    "\n",
    "    # define early stopping callback\n",
    "    earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "    \n",
    "    model_info = model.fit(x_train, y_train, \\\n",
    "            batch_size=BATCH_SIZE, \\\n",
    "            epochs=EPOCHS, \\\n",
    "            verbose=1, \\\n",
    "            validation_data=(x_test, y_test) , \\\n",
    "            callbacks=[tbCallBack])\n",
    "    \n",
    "    # end timer and print the time taken to train model\n",
    "    end = time.time()\n",
    "    print(\"\\nModel took %0.2f seconds to train\"%(end - start))\n",
    "    # display graph accuracy and loss\n",
    "    plot_model_history(model_info,MODEL_NAME)\n",
    "\n",
    "    # compute test accuracy\n",
    "    acc=accuracy(x_test, y_test, model)\n",
    "    print(\"Accuracy on test data is: %0.2f\"%acc)\n",
    "    return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxLoY_EUKhw0"
   },
   "outputs": [],
   "source": [
    "def export_model(model, MODEL_NAME):\n",
    "    # Save trained model in .h5 file\n",
    "    print(\"\\n[INFO] exporting model to .h5 file\")\n",
    "    model.save(f\"out/{MODEL_NAME}-{BATCH_SIZE}-{EPOCHS}.h5\")\n",
    "    print(\"\\n[INFO] model saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hW4NmNDtN27"
   },
   "outputs": [],
   "source": [
    "def cnn_model_1():\n",
    "    MODEL_NAME='CNN_model_1'\n",
    "    model=build_model_1(MODEL_NAME)\n",
    "    if not path.exists(f'out\\\\{MODEL_NAME}'):\n",
    "        print(\"\\n[info] out folder not available, creating folder 'out\\MODEL NAME' in the root directory\")\n",
    "        os.mkdir(f'out\\\\{MODEL_NAME}')\n",
    "    acc=train(model, x_train, y_train, x_test, y_test,MODEL_NAME)\n",
    "    Accuracy[MODEL_NAME]=acc\n",
    "    export_model(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_2():\n",
    "    MODEL_NAME='CNN_model_2'\n",
    "    model=build_model_2(MODEL_NAME)\n",
    "    if not path.exists(f'out\\\\{MODEL_NAME}'):\n",
    "        print(\"\\n[info] out folder not available, creating folder 'out\\MODEL NAME' in the root directory\")\n",
    "        os.mkdir(f'out\\\\{MODEL_NAME}')\n",
    "    acc=train(model, x_train, y_train, x_test, y_test,MODEL_NAME)\n",
    "    Accuracy[MODEL_NAME]=acc\n",
    "    export_model(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lenet_model():\n",
    "    MODEL_NAME='LeNET-5'\n",
    "    model=LeNet5()\n",
    "    if not path.exists(f'out\\\\{MODEL_NAME}'):\n",
    "        print(\"\\n[info] out folder not available, creating folder 'out\\MODEL NAME' in the root directory\")\n",
    "        os.mkdir(f'out\\\\{MODEL_NAME}')\n",
    "    acc=train(model, x_train, y_train, x_test, y_test,MODEL_NAME)\n",
    "    Accuracy[MODEL_NAME]=acc\n",
    "    export_model(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-r2_nngSKjsQ",
    "outputId": "144cd93e-8172-4dd6-bf62-4e174d9fbe3d"
   },
   "outputs": [],
   "source": [
    "Accuracy=dict()\n",
    "\n",
    "print(\"\\n[INFO] loading data from the dataset into variables\")\n",
    "x_train, y_train, x_test, y_test = load_data(\"dataset_pickles\\dataset_classes.pickle\")\n",
    "cnn_model_1()\n",
    "cnn_model_2()\n",
    "Lenet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(Accuracy.keys(),Accuracy.values(),color=[0.2,0.4,0.6,0.6])\n",
    "plt.title('Accuracy Comparison Chart')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.ylim(0,100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving Chart in image format\")\n",
    "fig.savefig('Comparison chart.jpeg')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "mlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
